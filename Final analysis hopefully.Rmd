---
title: "Association between sleep quality and pain in older adults"
author: "Pedro Henrique Brant"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

## Introduction

In this manuscript, we're going to conduct an analysis into the ELSI Dataset. This is a modified version for usage in the Principles and Practice of Clinical Research program of Harvard T.H. Chan School of Public Health.

The aim here is to replicate the analysis done in a [previous paper](https://pubmed.ncbi.nlm.nih.gov/34968438/) and see if the results also apply to the sample that was included in the [ELSI Brazil](https://elsi.cpqrr.fiocruz.br/en/home-english/).

First order of business is to download the dataset we're going to be analyzing, which was kindly provided by PPCR staff.

```{r, message=FALSE, warning=FALSE}
## Loading the necessary libraries
library(tidyverse)
library(haven)
library(broom)
library(ggplot2)
library(gtsummary)
```

```{r}

## Url provided by PPCR staff
url <- 'https://contattafiles.s3.us-west-1.amazonaws.com/tnt45405/T9gKrWnaRr5K0yT/FINAL%20-%20ELSI_students.dta'

## Using the read_dta function from haven to read the .dta file created in STATA
PPCRdata <- read_dta(url)

## Removing the url from memory as it is no longer useful
rm(url)

## Transforming to tibble in order to increase readability
PPCRdata <- as_tibble(PPCRdata)
PPCRdata

```

PPCR Staff has described the variables included in this dataset with the following:
![Variables in modified dataset](https://contattafiles.s3.us-west-1.amazonaws.com/tnt45405/3Rq88vSRw93ITf6/Screen%20Shot%202023-10-04%20at%201.03.35%20PM.png)

### Adjusting Variables for the Analysis

Let's now look at the some of the individual variables to understand what they mean
```{r}
unique(PPCRdata$pain)
unique(PPCRdata$p_intensity)
unique(PPCRdata$sleepquality)
unique(PPCRdata$sleepproblems)
```

We can then see that *pain* and *sleepproblems* are binary variables, while *p_intensity* and *sleepquality* are ordinal variables, although they aren't coded in this manner yet.

Now let's transform *p_intensity* and *sleepquality* into ordinal variables and *pain* and *sleepproblems* into binary variables, as they were read as numerical variables with labels.

```{r}
## Using the as_factor function from haven to transform the variables 
## with the labels as names for the levels in the factors
PPCRdata$sleepquality <- as_factor(PPCRdata$sleepquality, ordered = TRUE)
PPCRdata$p_intensity <- as_factor(PPCRdata$p_intensity, ordered = TRUE)
PPCRdata$pain <- as_factor(PPCRdata$pain)
PPCRdata$sleepproblems <- as_factor(PPCRdata$sleepproblems)


levels(PPCRdata$sleepquality)

## Reversing the order of factors, as initially the order was wrong in sleepquality
PPCRdata$sleepquality <- fct_rev(PPCRdata$sleepquality)
levels(PPCRdata$sleepquality)

```

Other variables that we're going to use in our model that haven't been coded properly as well include: *depression*, *alcohol*, *fracture*, *cancer*, *diabetes*, *dementia*, *arthritis*, *heartdisease* and *lungdisease*.
```{r}
## Showing that the variables are coded as numerical variables
unique(PPCRdata$depression)

## Commented the other variables for brevity, but they were all numerical
## unique(PPCRdata$sex)
## unique(PPCRdata$alcohol)
## unique(PPCRdata$fracture)
## unique(PPCRdata$cancer)
## unique(PPCRdata$diabetes)
## unique(PPCRdata$dementia)
## unique(PPCRdata$arthritis)
## unique(PPCRdata$heartdisease)
## unique(PPCRdata$lungdisease)

## Using the as_factor function from haven to transform the variables 
## with the labels as names for the levels in the factors
PPCRdata$depression <- as_factor(PPCRdata$depression)
PPCRdata$sex <- as_factor(PPCRdata$sex)
PPCRdata$alcohol <- as_factor(PPCRdata$alcohol)
PPCRdata$fracture <- as_factor(PPCRdata$fracture)
PPCRdata$cancer <- as_factor(PPCRdata$cancer)
PPCRdata$diabetes <- as_factor(PPCRdata$diabetes)
PPCRdata$dementia <- as_factor(PPCRdata$dementia)
PPCRdata$arthritis <- as_factor(PPCRdata$arthritis)
PPCRdata$heartdisease <- as_factor(PPCRdata$heartdisease)
PPCRdata$lungdisease <- as_factor(PPCRdata$lungdisease)

## Converting age to numeric

PPCRdata$age <- as.numeric(PPCRdata$age)
```
For completeness, let's check all of the variables we're going to use together in a summary
```{r}
PPCRdata %>% dplyr::select(age,bmi,sex,pain,p_intensity,sleepquality,sleepproblems,depression,
                    alcohol,fracture,cancer,diabetes,dementia,arthritis,
                    heartdisease,lungdisease) %>% tbl_summary(
                            statistic = list(
                                    all_continuous() ~ "{mean} ({sd})",
                                    all_categorical() ~ "{n} ({p}%)")
                    ) %>%
                modify_header(label = "**Variable**") %>%
                modify_caption("Subjects baseline characteristics") %>%
                bold_labels()
```
At this point we have coded all the variables correctly, so we can proceed with the analysis.

## Analysis
### Association between *pain* and *sleepquality*
#### Unadjusted Analysis
This analysis checks for the association between the *pain* variable and the *sleepquality* variable, without adjustments. As *pain* is a binary variable, we're going to run a logistic regression.

```{r}
## using the generalized linear model function 
## with the family = "binomial" to create a logistical
## regression
model0 <- glm (data = PPCRdata, formula = pain ~ sleepquality,
               family = "binomial")
summary(model0)
```

As the independent variable is coded as ordinal, the interpretation isn't completely straightforward. To make it simpler, let's start by calculating confidence intervals (CI) and then exponentiating them together with the coefficients to obtain the odds ratios and their respective CI's.

```{r message=FALSE, warning=FALSE}

## coef(model0) extracts the coefficients from the model
## confint(model0) calculates confidence intervals (95%)
## cbind then creates a table by joining the two by column
## finally, we exponentiate all the results using the base e
## in order to transform logit units into regular units

exp(cbind(OR = coef(model0),confint(model0)))

## another way, which is simpler and does the same, is to use
## the broom::tidy function

model0Tidy <- tidy(model0, conf.int = TRUE, exponentiate = TRUE)
model0Tidy %>% rename(Odds.Ratio = estimate) -> model0Tidy
model0Tidy

## let's plot these coefficients and their CI's to increase
## readability

model0Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                ## inserting a point for the odds ratio
                geom_point() +
                ## drawing a line at the 1 to improve readability
                geom_vline(xintercept = 1, lty = 4) +
                ## drawing an horizontal line to represent the 
                ## confidence interval
                geom_errorbarh() +
                ## reordering the categorical variables in the
                ## y-axis to improve readability
                ## also removing the intercept, as it's not 
                ## relevant for interpretation
                scale_y_discrete(limits = c('sleepquality.L',
                                            'sleepquality.Q',
                                            'sleepquality.C',
                                            'sleepquality^4'))

```

The p-value of the term *sleepquality.L* being significant means that there is a statistically significant **linear** association between <u>increasing</u> *sleepquality* values and <u>decreasing</u> the probability of *pain* being present (due to the less than 1 Odds Ratio).

We can also see that our model finds a significant relationship between *sleepquality.C* and *pain*. This finding is a little bit harder to interpret, but according to [this stack overflow post](https://stackoverflow.com/questions/57297771/interpretation-of-l-q-c-4-for-logistic-regression), we can interpret the third order polynomial as [jerk](https://en.wikipedia.org/wiki/Jerk_(physics)).

---

A different approach would be to either consider the variable as continuous or categorical. As we don't have to test for any assumptions in order to consider it categorical, let's proceed with that first.

```{r warning=FALSE}
## changing the variable to categorical
PPCRdata$sleepquality <- factor(PPCRdata$sleepquality, ordered = FALSE)

## running the model
model1 <- glm (data = PPCRdata, formula = pain ~ sleepquality,
               family = "binomial")
summary(model1)

## Let's proceed with the same transformations we did 
## when we built the model with the variable considered
## as ordinal, in order to improve readability

model1Tidy <- tidy(model1, conf.int = TRUE, exponentiate = TRUE)
model1Tidy %>% rename(Odds.Ratio = estimate) -> model1Tidy
model1Tidy

## Let's also plot this one for increased readability

model1Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                ## inserting a point for the odds ratio
                geom_point() +
                ## drawing a line at the 1 to improve readability
                geom_vline(xintercept = 1, lty = 4) +
                ## drawing an horizontal line to represent the 
                ## confidence interval
                geom_errorbarh() +
                ## changing the order to increase readability
                ## and removing the intercept again
                scale_y_discrete(limits = c('sleepqualityBad',
                                            'sleepqualityFair',
                                            'sleepqualityGood',
                                            'sleepqualityVery good'))
                

## reestablishing the variable as ordinal
PPCRdata$sleepquality <- factor(PPCRdata$sleepquality, ordered = TRUE)
```
This analysis allows us to determine that, when using a reference level of *sleepquality* that is **very bad**, the odds of experiencing *pain* when *sleepquality* increases are significantly lower (the odds ratio of the comparison of each other level with the very bad level of sleep quality can be seen in the table and plot above).

---

In this next model, we're going to consider sleepquality as a continuous variable.

```{r}
## doing the transformation and saving on another variable to not lose the
## categorical information (names for each level)
PPCRdata %>% mutate(sleepquality = as.numeric(sleepquality)) -> dataNumeric

```
Now that the variable is transformed to numeric, let's run the model again.

```{r}

glm (data = dataNumeric, formula = pain ~ sleepquality, 
     family = "binomial") -> model2
model2 %>% tidy(confint = TRUE, exponentiate = TRUE) %>% 
        rename(Odds.Ratio = estimate) -> model2Tidy
summary(model2)
model2Tidy

```
In order to determine which model is best, we're going to look at the AIC values. It looks like changing the variable to continues increases the AIC, which tells us that the model is behaving worse than the categorical. Let's keep it categorical, then.

---

#### Adjusted Analysis
This analysis checks for the association between the *pain* variable and the *sleepquality* variable, adjusting the model for bmi, comorbidities and depression, as was done in the original article. As *pain* is a binary variable, we're going to run a logistic regression.

```{r}
model3 <- glm(data = PPCRdata, formula = pain ~ sleepquality + age + bmi + 
                      depression + alcohol + fracture + cancer + diabetes + 
                      dementia + arthritis + heartdisease + lungdisease,
                family = "binomial")
summary(model3)
```

The interpretation of this model regarding our main independent variable, *sleepquality*, is hard to do, as the model is considering it as ordinal. Let's run it again with the model considering it as categorical.

```{r}
## changing the variable to categorical
PPCRdata$sleepquality <- factor(PPCRdata$sleepquality, ordered = FALSE)

## running the model
model4 <- glm (data = PPCRdata, formula = pain ~ sleepquality + age + 
                       depression + alcohol + fracture + cancer + 
                       diabetes + dementia + arthritis + heartdisease +
                       lungdisease, family = "binomial")
summary(model4)

## reestablishing the variable as ordinal
PPCRdata$sleepquality <- factor(PPCRdata$sleepquality, ordered = TRUE)
```

We can present these results in a better fashion.

```{r}

## Let's proceed with the same code we used for the  
## unadjusted analysis, only changing the model used

model4Tidy <- tidy(model4, conf.int = TRUE, exponentiate = TRUE)
model4Tidy %>% rename(Odds.Ratio = estimate) -> model4Tidy
model4Tidy

```

These are the odds ratios of *pain* being present when we compare the different levels of the *sleepquality* variable to its baseline: very bad. We can also see the same measurements calculated for all the covariates.

Let's look at a plot:

```{r}
model4Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                geom_point() +
                geom_vline(xintercept = 1, lty = 4) +
                geom_errorbarh()
```

Here we can see all of the associations with the *pain* variable in our model.

#### Testing the assumptions of the model

At this point, I haven't yet learned how to properly test for the assumptions of the logistic regression model. On a later opportunity, I'll try to remedy this situation. For now, I'll include some commands that were listed as useful in the [R you ready for R?](https://bookdown.org/wadetroberts/r-you-ready-for-r/multiple-logistic-regression.html#model-fit-statistics-for-multiple-logistic-regression) e-book. 

```{r warning= FALSE}
library(blorr)
blr_model_fit_stats(model4)
blr_test_hosmer_lemeshow(model4)
blr_roc_curve(blr_gains_table(model4))
car::vif(model4)
```

### Association between *sleepquality* and *pain*

In order to do this analysis I'll try to follow the instructions from the [UCLA OARC - Ordinal Logistic Regression | R Data Analysis Example](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/).

As the original article by [Montelh√£o et al](https://pubmed.ncbi.nlm.nih.gov/34968438/) tested for bidirectional associations, let's try to replicate that as well. In this case, the dependent variable is ordinal, therefore we will run an ordinal logistical regression.

```{r warning = FALSE, message = FALSE}
## loading the library required to run the model
library(MASS)

## running the model
model5 <- polr (data = PPCRdata, formula = sleepquality ~ pain + depression + 
                       alcohol + fracture + cancer + diabetes + dementia +
                       arthritis + heartdisease + lungdisease, Hess = TRUE)
summary(model5)
```

```{r}
## tidy(model5, exponentiate = TRUE, p.values = TRUE, conf.int = TRUE)
```

The tidy function is not working for the polr model, even though it should. I tried to debug it, but couldn't. I will then describe a more manual approach, as was described in the [UCLA Office of Advanced Research Computing (OARC)](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/) page for Ordinal Regression.


```{r}
## getting the coefficients
ctable <- coef(summary(model5))

## getting the respective p-values from the normal distribution
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## creating a table with the respective p-values added
ctable <- cbind(ctable, "p value" = p)
ctable

## creating confidence intervals
ci<-confint.default(model5)
colnames(ci) <- c("conf.low", "conf.high")

## exponentiating the log-odds and the confidence intervals
## in order to create the odds-ratios and the respective CI's
model5OddsRatio <- exp(cbind(OR = coef(model5), ci))
## converting rownames to columns, as this will be necessary to build the plot
model5OddsRatio <- as_tibble(rownames_to_column(as.data.frame(model5OddsRatio)))
model5OddsRatio %>% rename(term = rowname) -> model5OddsRatio

```
Let's build a plot using these values.

```{r}
model5OddsRatio %>% ggplot (aes(OR, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                geom_point() +
                geom_vline(xintercept = 1, lty = 4) +
                geom_errorbarh()
```

The plot allows us to visually determine that the presence of *pain* decreases the odds of *sleepquality* being higher. Unfortunately, the model has a high AIC.

#### Testing for the Proportional Odds Assumption

This is something to consider further on. At this point, I haven't yet figured out exactly how to do it, but I'll try to follow the instructions from the [Office of Advanced Research Computing](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/) on another day.

