---
title: "Association between sleep quality and pain in older adults"
author: "Pedro Henrique Brant"
date: "`r Sys.Date()`"
output:
  html_document: 
        toc: true
        toc_depth: 4
        theme: united
  pdf_document: default
---

## Introduction

In this manuscript, we're going to conduct an analysis into the ELSI Dataset. This is a modified version for usage in the Principles and Practice of Clinical Research program of Harvard T.H. Chan School of Public Health.

The aim here is to replicate the analysis done in a [previous paper](https://pubmed.ncbi.nlm.nih.gov/34968438/) and see if the results also apply to the sample that was included in the [ELSI Brazil](https://elsi.cpqrr.fiocruz.br/en/home-english/).

First order of business is to download the dataset we're going to be analyzing, which was kindly provided by PPCR staff.

```{r, message=FALSE, warning=FALSE}
## Loading the necessary libraries
library(tidyverse)
library(haven)
library(broom)
library(ggplot2)
library(gtsummary)
```

```{r}

## Url provided by PPCR staff
url <- 'https://ryver-prd-files.s3.us-west-2.amazonaws.com/tnt45405/T9gKrWnaRr5K0yT/FINAL%20-%20ELSI_students.dta'

## Using the read_dta function from haven to read the .dta file created in STATA
PPCRdata <- read_dta(url)

## Removing the url from memory as it is no longer useful
rm(url)

## Transforming to tibble in order to increase readability
PPCRdata <- as_tibble(PPCRdata)
PPCRdata

```

PPCR Staff has described the variables included in this dataset with the following:
![Variables in modified dataset](https://ryver-prd-files.s3.us-west-2.amazonaws.com/tnt45405/3Rq88vSRw93ITf6/Screen%20Shot%202023-10-04%20at%201.03.35%20PM.png)

### Adjusting Variables for the Analysis

Let's now look at the some of the individual variables to understand what they mean
```{r}
unique(PPCRdata$pain)
unique(PPCRdata$p_intensity)
unique(PPCRdata$sleepquality)
unique(PPCRdata$sleepproblems)
```

We can then see that *pain* and *sleepproblems* are binary variables, while *p_intensity* and *sleepquality* are ordinal variables, although they aren't coded in this manner yet.

Now let's transform *p_intensity* and *sleepquality* into categorical variables and *pain* and *sleepproblems* into dichotomous variables, as they were read as numerical variables with labels.

```{r}
## Using the as_factor function from haven to transform the variables 
## with the labels as names for the levels in the factors
PPCRdata$sleepquality <- as_factor(PPCRdata$sleepquality)
PPCRdata$p_intensity <- as_factor(PPCRdata$p_intensity)
PPCRdata$pain <- as_factor(PPCRdata$pain)
PPCRdata$sleepproblems <- as_factor(PPCRdata$sleepproblems)


levels(PPCRdata$sleepquality)

## Reversing the order of factors, as initially the order was wrong in sleepquality
PPCRdata$sleepquality <- fct_rev(PPCRdata$sleepquality)
levels(PPCRdata$sleepquality)

```

Other variables that we're going to use in our model that haven't been coded properly as well include: *depression*, *alcohol*, *fracture*, *cancer*, *diabetes*, *dementia*, *arthritis*, *heartdisease* and *lungdisease*.

```{r}
## Showing that the variables are coded as numerical variables
unique(PPCRdata$depression)

## Commented the other variables for brevity, but they were all numerical
## unique(PPCRdata$sex)
## unique(PPCRdata$alcohol)
## unique(PPCRdata$fracture)
## unique(PPCRdata$cancer)
## unique(PPCRdata$diabetes)
## unique(PPCRdata$dementia)
## unique(PPCRdata$arthritis)
## unique(PPCRdata$heartdisease)
## unique(PPCRdata$lungdisease)

## Using the as_factor function from haven to transform the variables 
## with the labels as names for the levels in the factors
PPCRdata$depression <- as_factor(PPCRdata$depression)
PPCRdata$sex <- as_factor(PPCRdata$sex)
PPCRdata$alcohol <- as_factor(PPCRdata$alcohol)
PPCRdata$fracture <- as_factor(PPCRdata$fracture)
PPCRdata$cancer <- as_factor(PPCRdata$cancer)
PPCRdata$diabetes <- as_factor(PPCRdata$diabetes)
PPCRdata$dementia <- as_factor(PPCRdata$dementia)
PPCRdata$arthritis <- as_factor(PPCRdata$arthritis)
PPCRdata$heartdisease <- as_factor(PPCRdata$heartdisease)
PPCRdata$lungdisease <- as_factor(PPCRdata$lungdisease)

## Converting age to numeric

PPCRdata$age <- as.numeric(PPCRdata$age)
```
Let's now create a table summarizing all the information we have collected.

```{r}
PPCRdata %>% dplyr::select(age,bmi,sex,pain,p_intensity,sleepquality,
                           sleepproblems,depression,alcohol,fracture,cancer,
                           diabetes,dementia,arthritis,heartdisease,
                           lungdisease) %>% 
        tbl_summary(statistic = list(all_continuous() ~ "{mean} ({sd})",
                                    all_categorical() ~ "{n} ({p}%)")) %>%
                modify_header(label = "**Variable**") %>%
                modify_caption("Subjects baseline characteristics") %>%
                bold_labels()
```
At this point we have coded all the variables correctly, so we can proceed with the analysis.

## Analysis
### Association between *pain* and *sleepquality*
#### Unadjusted Analysis
This analysis checks for the association between the *pain* variable and the *sleepquality* variable, without adjustments. As *pain* is a binary variable, we're going to run a logistic regression.

```{r warning=FALSE}
## using the generalized linear model function 
## with the family = "binomial" to create a logistical
## regression

model1 <- glm (data = PPCRdata, formula = pain ~ sleepquality,
               family = "binomial")
summary(model1)

## coef(model1) extracts the coefficients from the model
## confint(model1) calculates confidence intervals (95%)
## cbind then creates a table by joining the two by column
## finally, we exponentiate all the results using the base e
## in order to transform logit units into regular units

exp(cbind(OR = coef(model1),confint(model1)))

## another way, which is simpler and does the same, is to use
## the broom::tidy function

model1Tidy <- tidy(model1, conf.int = TRUE, exponentiate = TRUE)
model1Tidy %>% rename(Odds.Ratio = estimate) -> model1Tidy
model1Tidy

## let's plot these coefficients and their CI's to increase
## readability

model1Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                ## inserting a point for the odds ratio
                geom_point() +
                ## drawing a line at the 1 to improve readability
                geom_vline(xintercept = 1, lty = 4) +
                ## drawing an horizontal line to represent the 
                ## confidence interval
                geom_errorbarh() +
                ## removing the intercept again
                scale_y_discrete(
                        limits = setdiff(model1Tidy$term, "(Intercept)"))
```
This analysis allows us to determine that, when using a reference level of *sleepquality* that is **very bad**, the odds of experiencing *pain* when *sleepquality* increases are significantly lower (the odds ratio of the comparison of each other level with the very bad level of sleep quality can be seen in the table and plot above).

---

##### Sensitivity Analysis

In this next model, we're going to consider sleepquality as a continuous variable.

```{r}
## doing the transformation and saving on another variable to not lose the
## categorical information (names for each level)
PPCRdata %>% mutate(sleepqualitynum = 
        case_when(PPCRdata$sleepquality == 'Very bad' ~ 1,
                  PPCRdata$sleepquality == 'Bad' ~ 2,
                  PPCRdata$sleepquality == 'Fair' ~ 3,
                  PPCRdata$sleepquality == 'Good' ~ 4,
                  PPCRdata$sleepquality == 'Very good' ~ 5)) -> PPCRdata
```

Now that the variable is transformed to numeric, let's run the model again.

```{r, warning = FALSE}

glm (data = PPCRdata, formula = pain ~ sleepqualitynum, 
     family = "binomial") -> model2
model2 %>% tidy(conf.int = TRUE, exponentiate = TRUE) %>% 
        rename(Odds.Ratio = estimate) -> model2Tidy
model2Tidy

model2Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                ## inserting a point for the odds ratio
                geom_point() +
                ## drawing a line at the 1 to improve readability
                geom_vline(xintercept = 1, lty = 4) +
                ## drawing an horizontal line to represent the 
                ## confidence interval
                geom_errorbarh() +
                scale_y_discrete(
                        limits = setdiff(model2Tidy$term, "(Intercept)"))

```

In order to determine which model is best, we're going to look at the AIC values. It looks like changing the variable to continues increases the AIC, which tells us that the model is behaving worse than the categorical. Let's keep it categorical, then.

---

#### Adjusted Analysis
This analysis checks for the association between the *pain* variable and the *sleepquality* variable, adjusting the model for bmi, comorbidities and depression, as was done in the original article. As *pain* is a binary variable, we're going to run a logistic regression.

```{r}
model3 <- glm(data = PPCRdata, formula = pain ~ sleepquality + age + bmi + 
                      depression + alcohol + fracture + cancer + diabetes + 
                      dementia + arthritis + heartdisease + lungdisease,
                family = "binomial")
summary(model3)
```
Let's adjust the results and plot the odds ratios.

```{r, warning = FALSE}

model3Tidy <- tidy(model3, conf.int = TRUE, exponentiate = TRUE)
model3Tidy %>% rename(Odds.Ratio = estimate) -> model3Tidy
model3Tidy

model3Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                ## inserting a point for the odds ratio
                geom_point() +
                ## drawing a line at the 1 to improve readability
                geom_vline(xintercept = 1, lty = 4) +
                ## drawing an horizontal line to represent the 
                ## confidence interval
                geom_errorbarh() +
                scale_y_discrete(
                        limits = setdiff(model3Tidy$term, "(Intercept)"))

```

If we refer to the analysis of the unadjusted model, the results are the same for the *sleepquality* variable. In summary, increasing levels of sleep quality are decrease the odds of pain being present.

##### Sensitivity Analysis

We can also test how the adjusted model behaves with sleep quality as a continuous variable.

```{r, warning = FALSE}

model4 <- glm(data = PPCRdata, formula = pain ~ sleepqualitynum + age + bmi + 
                      depression + alcohol + fracture + cancer + diabetes + 
                      dementia + arthritis + heartdisease + lungdisease,
                family = "binomial")
summary(model4)

model4Tidy <- tidy(model4, conf.int = TRUE, exponentiate = TRUE)
model4Tidy %>% rename(Odds.Ratio = estimate) -> model4Tidy
model4Tidy

model4Tidy %>% ggplot (aes(Odds.Ratio, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                ## inserting a point for the odds ratio
                geom_point() +
                ## drawing a line at the 1 to improve readability
                geom_vline(xintercept = 1, lty = 4) +
                ## drawing an horizontal line to represent the 
                ## confidence interval
                geom_errorbarh() +
                scale_y_discrete(
                        limits = setdiff(model4Tidy$term, "(Intercept)"))

```

The results point towards increases in the continuous variable also being significantly associated with a decrease in the odds of pain being present. Looking at the AIC, it still seems as if the model with sleepquality coded as categorical behaves better.

#### Testing the assumptions of the model

At this point, I haven't yet learned how to properly test for the assumptions of the logistic regression model. On a later opportunity, I'll try to remedy this situation. For now, I'll include some commands that were listed as useful in the [R you ready for R?](https://bookdown.org/wadetroberts/r-you-ready-for-r/multiple-logistic-regression.html#model-fit-statistics-for-multiple-logistic-regression) e-book. 

```{r warning= FALSE}
library(blorr)
blr_model_fit_stats(model3)
blr_test_hosmer_lemeshow(model3)
blr_roc_curve(blr_gains_table(model3))
car::vif(model3)
```

### Association between *sleepquality* and *pain*
#### Ordinal Regression
##### Adjusted Analysis
In order to do this analysis I'll try to follow the instructions from the [UCLA OARC - Ordinal Logistic Regression | R Data Analysis Example](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/).

As the original article by [Montelhão et al](https://pubmed.ncbi.nlm.nih.gov/34968438/) tested for bidirectional associations, let's try to replicate that as well. In this case, the dependent variable is ordinal, therefore we will run an ordinal logistical regression.

```{r warning = FALSE, message = FALSE}
## creating an ordinal version of sleepquality

PPCRdata %>% mutate (sleepqualityord = factor(PPCRdata$sleepquality,
                                              ordered = TRUE)) -> PPCRdata

## loading the library required to run the model
library(MASS)

## running the model
model5 <- polr (data = PPCRdata, formula = sleepqualityord ~ pain + depression + 
                       alcohol + fracture + cancer + diabetes + dementia +
                       arthritis + heartdisease + lungdisease, Hess = TRUE)
summary(model5)
```

```{r}
## tidy(model5, exponentiate = TRUE, p.values = TRUE, conf.int = TRUE)
```

The tidy function is not working for the polr model, even though it should. I tried to debug it, but couldn't. I will then describe a more manual approach, as was described in the [UCLA Office of Advanced Research Computing (OARC)](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/) page for Ordinal Regression.


```{r}
## getting the coefficients
ctable <- coef(summary(model5))

## getting the respective p-values from the normal distribution
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2

## creating a table with the respective p-values added
ctable <- cbind(ctable, "p value" = p)
ctable

## creating confidence intervals
ci<-confint.default(model5)
colnames(ci) <- c("conf.low", "conf.high")

## exponentiating the log-odds and the confidence intervals
## in order to create the odds-ratios and the respective CI's
model5OddsRatio <- exp(cbind(OR = coef(model5), ci))
## converting rownames to columns, as this will be necessary to build the plot
model5OddsRatio <- as_tibble(rownames_to_column(as.data.frame(model5OddsRatio)))
model5OddsRatio %>% rename(term = rowname) -> model5OddsRatio

```
Let's build a plot using these values.

```{r}
model5OddsRatio %>% ggplot (aes(OR, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                geom_point() +
                geom_vline(xintercept = 1, lty = 4) +
                geom_errorbarh()
```

The plot allows us to visually determine that the presence of *pain* decreases the odds of *sleepquality* being higher. Unfortunately, the model has a high AIC.

##### Unadjusted Analysis

In order to be able to compare the adjusted analysis, let's proceed with one that is unadjusted as well.

```{r}
## this code is equivalent to the one used for the adjusted analysis, just 
## with no covariates added to the model
model6 <- polr (data = PPCRdata, formula = sleepqualityord ~ pain, Hess = TRUE)
summary(model6)

## getting the coefficients
ctable2 <- coef(summary(model6))

## getting the respective p-values from the normal distribution
p <- pnorm(abs(ctable2[, "t value"]), lower.tail = FALSE) * 2

## creating a table with the respective p-values added
ctable2 <- cbind(ctable2, "p value" = p)

## creating confidence intervals
ci<-confint.default(model6)
colnames(ci) <- c("conf.low", "conf.high")

## exponentiating the log-odds and the confidence intervals
## in order to create the odds-ratios and the respective CI's
model6OddsRatio <- exp(cbind(OR = coef(model6), ci))
## converting rownames to columns, as this will be necessary to build the plot
model6OddsRatio <- as_tibble(rownames_to_column(as.data.frame(model6OddsRatio)))
model6OddsRatio %>% rename(term = rowname) -> model6OddsRatio
model6OddsRatio

## building a plot
model6OddsRatio %>% ggplot (aes(OR, term, xmin = conf.low,
                           xmax = conf.high, height = 0)) +
                geom_point() +
                geom_vline(xintercept = 1, lty = 4) +
                geom_errorbarh()
```

We need to check what the warning means, but the presence of pain reduces the odds of increased sleep quality in this model. The AIC is huge, as should be expected of a model that only has one predictor and that predictor is a dichotomous variable.

##### Testing for the Proportional Odds Assumption

This is something to consider further on. At this point, I haven't yet figured out exactly how to do it, but I'll try to follow the instructions from the [Office of Advanced Research Computing](https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/) on another day.

```{r, messages = FALSE, warning = FALSE}
## Loading the library that is needed to conduct the visual analysis of the
## proportional odds assumption

library (Hmisc)

sf <- function(y) {
  c('Y>=1' = qlogis(mean(y >= 1)),
    'Y>=2' = qlogis(mean(y >= 2)),
    'Y>=3' = qlogis(mean(y >= 3)),
    'Y>=4' = qlogis(mean(y >= 4)),
    'Y>=5' = qlogis(mean(y >= 5)),
    'Y>=6' = qlogis(mean(y >= 6)))
}

(s <- with(PPCRdata, summary(as.numeric(sleepqualityord) ~ pain + depression + 
                       alcohol + fracture + cancer + diabetes + dementia +
                       arthritis + heartdisease + lungdisease, fun=sf)))

s[, 6] <- s[, 6] - s[, 5]
s[, 5] <- s[, 5] - s[, 4]
s[, 4] <- s[, 4] - s[, 3]
s[, 3] <- s[, 3] - s[, 3]

s

plot(s, which=1:6, xlab='logit', main=' ', xlim=c(-2.8,0))

```

It doesn't look like the proportional odds assumption holds.

#### Logistic Regression
In order to conduct a logistic regression using sleep quality as a dependent variable, we need to first convert it to a dichotomous variable.

```{r}



```